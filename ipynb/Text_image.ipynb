{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb"
      ],
      "metadata": {
        "id": "iqhnNypimyUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "559cdbe3-a113-4d23-87c3-47e1e56c3742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-27 06:33:40--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.6.1/cloudflared-linux-amd64.deb [following]\n",
            "--2025-06-27 06:33:40--  https://github.com/cloudflare/cloudflared/releases/download/2025.6.1/cloudflared-linux-amd64.deb\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/f2a50f07-6f2f-47cd-8a16-5d3dca82800f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250627%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250627T063340Z&X-Amz-Expires=1800&X-Amz-Signature=62ad3dc7e065cd1728ad4adc596981b0e805b08662a305dd40e8878bacf5dac2&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-06-27 06:33:40--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/f2a50f07-6f2f-47cd-8a16-5d3dca82800f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250627%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250627T063340Z&X-Amz-Expires=1800&X-Amz-Signature=62ad3dc7e065cd1728ad4adc596981b0e805b08662a305dd40e8878bacf5dac2&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20160292 (19M) [application/octet-stream]\n",
            "Saving to: ‚Äòcloudflared-linux-amd64.deb‚Äô\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  19.23M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-06-27 06:33:41 (269 MB/s) - ‚Äòcloudflared-linux-amd64.deb‚Äô saved [20160292/20160292]\n",
            "\n",
            "Selecting previously unselected package cloudflared.\n",
            "(Reading database ... 126308 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2025.6.1) ...\n",
            "Setting up cloudflared (2025.6.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir gt\n",
        "\n",
        "\n",
        "\n",
        "# It will recognize voice and give as propmt to LLM that will respond the answer it will convert to voice using speech AI Model"
      ],
      "metadata": {
        "id": "OPJmhnsyty_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L --retry 3 --retry-delay 2 \\\n",
        "  -H \"Authorization: Bearer 280c7103ccc07977a5673fb0d4fb2fdc\" \\\n",
        "  -A \"Mozilla/5.0\" \\\n",
        "  -o ./gt/proto.safetensors \\\n",
        "  \"https://civitai.com/api/download/models/265938?type=Model&format=SafeTensor&size=pruned&fp=fp16\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dINkvj3Dt0wE",
        "outputId": "3b1b622f-56df-4416-badd-8dcbd8e25bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   535    0   535    0     0    370      0 --:--:--  0:00:01 --:--:--   370\n",
            "100 6616M  100 6616M    0     0  83.1M      0  0:01:19  0:01:19 --:--:-- 39.9M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGTPtsHjPHo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aac6435-84c0-4bb4-d8ba-f2a388a3aec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "import subprocess\n",
        "import multiprocessing\n",
        "import socket\n",
        "import re\n",
        "import time\n",
        "import urllib.request\n",
        "from flask import Flask, request, jsonify, send_file\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "import torch\n",
        "import tempfile\n",
        "import imageio\n",
        "from io import BytesIO\n",
        "import imageio.plugins.ffmpeg\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "\n",
        "port = 5000\n",
        "app = Flask(__name__)\n",
        "pipe = None\n",
        "\n",
        "def wait_for_flask():\n",
        "    print(f\"‚è≥ Waiting for Flask to start on port {port}...\")\n",
        "    while True:\n",
        "        try:\n",
        "            with socket.create_connection((\"127.0.0.1\", port), timeout=1):\n",
        "                print(\"‚úÖ Flask is running locally.\")\n",
        "                break\n",
        "        except OSError:\n",
        "            time.sleep(1)\n",
        "\n",
        "def start_cloudflared():\n",
        "    wait_for_flask()\n",
        "    print(\"üåê Launching Cloudflare Tunnel...\")\n",
        "    process = subprocess.Popen(\n",
        "        [\"cloudflared\", \"tunnel\", \"--url\", f\"http://127.0.0.1:{port}\"],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "    )\n",
        "\n",
        "    for line in iter(process.stdout.readline, b''):\n",
        "        decoded = line.decode().strip()\n",
        "        print(\"üåê [cloudflared]:\", decoded)  # See all output\n",
        "        match = re.search(r\"https://.*trycloudflare.com\", decoded)\n",
        "        if match:\n",
        "            print(\"üîó Access ComfyUI here:\", match.group())\n",
        "            break\n",
        "\n",
        "@app.route(\"/t2i\", methods=[\"POST\"])\n",
        "def t2i():\n",
        "    try:\n",
        "        if not request.is_json:\n",
        "            return jsonify({'error': 'Request must be JSON'}), 400\n",
        "\n",
        "        prompt = request.json.get(\"prompt\")\n",
        "        if prompt is None:\n",
        "            return jsonify({'error': 'No prompt'}), 400\n",
        "\n",
        "        # Run inference\n",
        "        image = pipe(prompt=prompt, num_inference_steps=20).images[0]\n",
        "\n",
        "        buf = BytesIO()\n",
        "        image.save(buf, format=\"PNG\")\n",
        "        buf.seek(0)\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        return send_file(buf, mimetype=\"image/png\")\n",
        "\n",
        "        # return jsonify({\"video\": video_base64})\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "def start_flask():\n",
        "    global pipe\n",
        "    model_path = \"/content/gt/proto.safetensors\"\n",
        "\n",
        "    # Load SDXL model from safetensors\n",
        "    pipe = StableDiffusionXLPipeline.from_single_file(\n",
        "        model_path,\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "        variant=\"fp16\"\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    app.run(host=\"0.0.0.0\", port=port)\n",
        "\n",
        "def main():\n",
        "    multiprocessing.set_start_method(\"spawn\", force=True)\n",
        "\n",
        "    flask_proc = multiprocessing.Process(target=start_flask)\n",
        "    tunnel_proc = multiprocessing.Process(target=start_cloudflared)\n",
        "\n",
        "    flask_proc.start()\n",
        "    tunnel_proc.start()\n",
        "\n",
        "    # try:\n",
        "    #     while flask_proc.is_alive():\n",
        "    #         print(\"üü¢ Flask is running... keeping process alive.\")\n",
        "    #         time.sleep(60)\n",
        "    # except KeyboardInterrupt:\n",
        "    #     print(\"üõë Stopping...\")\n",
        "    #     flask_proc.terminate()\n",
        "    #     tunnel_proc.terminate()\n",
        "\n",
        "    flask_proc.join()\n",
        "    tunnel_proc.join()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py"
      ],
      "metadata": {
        "id": "rSKLRwAAmvog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de06a813-86b7-45a3-f536-1494ae59607e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-27 06:35:14.622588: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751006114.642640     794 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751006114.650184     794 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-27 06:35:29.627727: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751006129.667425     884 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751006129.680404     884 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-27 06:35:29.705125: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751006129.769082     885 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751006129.784876     885 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "‚è≥ Waiting for Flask to start on port 5000...\n",
            "Fetching 17 files:   0% 0/17 [00:00<?, ?it/s]\n",
            "model_index.json: 100% 609/609 [00:00<00:00, 5.08MB/s]\n",
            "\n",
            "scheduler_config.json: 100% 479/479 [00:00<00:00, 3.81MB/s]\n",
            "\n",
            "config.json: 100% 565/565 [00:00<00:00, 5.25MB/s]\n",
            "\n",
            "config.json: 100% 575/575 [00:00<00:00, 5.66MB/s]\n",
            "\n",
            "Fetching 17 files:   6% 1/17 [00:00<00:04,  3.75it/s]\n",
            "\n",
            "\n",
            "tokenizer_config.json:   0% 0.00/737 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "special_tokens_map.json: 100% 472/472 [00:00<00:00, 616kB/s]\n",
            "tokenizer_config.json: 100% 737/737 [00:00<00:00, 110kB/s]\n",
            "\n",
            "\n",
            "vocab.json: 1.06MB [00:00, 46.6MB/s]\n",
            "merges.txt: 525kB [00:00, 33.7MB/s]\n",
            "Fetching 17 files:  53% 9/17 [00:00<00:00, 20.27it/s]\n",
            "special_tokens_map.json: 100% 460/460 [00:00<00:00, 4.60MB/s]\n",
            "\n",
            "tokenizer_config.json: 100% 725/725 [00:00<00:00, 7.68MB/s]\n",
            "\n",
            "config.json: 100% 642/642 [00:00<00:00, 5.21MB/s]\n",
            "\n",
            "config.json: 1.68kB [00:00, 8.70MB/s]\n",
            "\n",
            "config.json: 100% 607/607 [00:00<00:00, 6.90MB/s]\n",
            "Fetching 17 files: 100% 17/17 [00:00<00:00, 22.91it/s]\n",
            "Loading pipeline components...: 100% 7/7 [00:02<00:00,  2.91it/s]\n",
            " * Serving Flask app '__mp_main__'\n",
            " * Debug mode: off\n",
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "‚úÖ Flask is running locally.\n",
            "üåê Launching Cloudflare Tunnel...\n",
            "üåê [cloudflared]: 2025-06-27T06:36:09Z INF Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "üåê [cloudflared]: 2025-06-27T06:36:09Z INF Requesting new quick Tunnel on trycloudflare.com...\n",
            "üåê [cloudflared]: 2025-06-27T06:36:15Z INF +--------------------------------------------------------------------------------------------+\n",
            "üåê [cloudflared]: 2025-06-27T06:36:15Z INF |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "üåê [cloudflared]: 2025-06-27T06:36:15Z INF |  https://zones-controversy-cathedral-percent.trycloudflare.com                             |\n",
            "üîó Access ComfyUI here: https://zones-controversy-cathedral-percent.trycloudflare.com\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:36:24] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:36:24] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "100% 20/20 [00:16<00:00,  1.21it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:38:03] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.24it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:38:37] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.18it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:39:13] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.20it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:39:49] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.21it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:40:24] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.19it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:40:58] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.21it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:41:36] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.18it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:42:08] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.21it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:42:42] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.21it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:43:16] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.20it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:43:50] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.21it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:44:24] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.20it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:44:58] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.21it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:45:32] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.20it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:46:06] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.20it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:46:41] \"POST /t2i HTTP/1.1\" 200 -\n",
            "100% 20/20 [00:16<00:00,  1.25it/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Jun/2025 06:47:18] \"POST /t2i HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1SCCHTxtHs5b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}